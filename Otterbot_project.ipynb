{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KfqGZTsVPoY"
   },
   "source": [
    "# **OtterBots Group Project**\n",
    "## <em>Can a dog's attributes predict their intelligence?</em><br>\n",
    "CST383: Introduction to Data Science<br>\n",
    "Professor Ergezer<br>\n",
    "Kevin Mcnulty, Nadia Rahbany, Juli Shinozuka, Andrew Shiraki<br>\n",
    "02/14/2023<br><br>\n",
    "\n",
    "<b>Introduction</b>: Have you ever wondered if there are attributes that can help predict intelligence in a companion dog?  What we hope to discover is whether attributes like height, weight, demeanor, and energy level can indicate a dog's intelligence level.  Intelligence (or obedience) is the likelihood that a dog will obey commands and require fewer repititions to learn new commands.  The intelligence scoring does not take into account that some dogs are bred for tasks that does not require 'obedience' to humans and rely more on independent thinking to do their purpose.<br><br>\n",
    "\n",
    "<b>Datasets</b>: After data munging and cleaning is done and the three datasets used are merged into a final dataset, we assessed the attributes that might help in our analysis.  We discovered that 'Classification', 'obey', and the rep columns are all related, and thus we only need to use one as the target.  Our data exploration has revealed that 'weight_avg', 'height_avg', 'demeanor_value', and 'energy_level_value' can be possible predictors.  More exploration is needed to determine the best combination.<br><br>\n",
    "<b>Methods</b>: The machine learning algorithms we will use to train models that will predict dog intelligence via attributes will be kNN and Linear Regression.<br><br>\n",
    "\n",
    "Our goal is to train models that will predict the intelligence of a dog using selected features (height, weight, demeanor, and energy) as accurately as possible given the small dataset available.<br><br>\n",
    "\n",
    "Source of the CSV files:\n",
    "\n",
    "*   [Kaggle - Canine Intelligence and Size](https://www.kaggle.com/datasets/thedevastator/canine-intelligence-and-size?select=AKC+Breed+Info.csv) on Jan 31, 2023 (6pm)\n",
    "*   [Github - akcdata by tmfilho](https://github.com/tmfilho/akcdata) on Feb 4, 2023 (5pm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HRtwB3TL8pD"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iRy4jU5UFFAj"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38233/3800005354.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import zscore\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vuXmSl1LMHpQ"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **Data Processing and Cleaning**\n",
    "\n",
    "\n",
    "\n",
    "*   Create dataframes from the csv files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UDsLAeFyGHbw"
   },
   "outputs": [],
   "source": [
    "# URLs\n",
    "breed_info_url=\"./data/AKC_Breed_Info.csv\"\n",
    "intel_url = \"./data/dog_intelligence.csv\"\n",
    "groups_url = \"./data/akc-data-latest.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "41rX0IHYJjxs"
   },
   "outputs": [],
   "source": [
    "# create dataframes\n",
    "df1 = pd.read_csv(breed_info_url, index_col=0)\n",
    "df2 = pd.read_csv(intel_url, index_col=0)\n",
    "#df2.drop(columns=['obey'], inplace=True) # drop 'obey' column.\n",
    "df3 = pd.read_csv(groups_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTDzzReYXTbu"
   },
   "source": [
    "\n",
    "\n",
    "*   Clean and prepare df3 for later merger.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sgubv8BJJsno"
   },
   "outputs": [],
   "source": [
    "# Cleaning up df3 for what is needed or possibly useful\n",
    "df3.rename(columns={'Unnamed: 0': 'Breed'}, inplace=True)\n",
    "df3 = df3[['Breed', 'group', 'energy_level_value', 'demeanor_value']]\n",
    "df3.drop(df3[df3['group'] == 'Foundation Stock Service'].index, inplace=True)\n",
    "df3.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOTy3q-GWvH8"
   },
   "source": [
    "*   Rename entries where a dog breed has many different spellings across the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4-WpggqAJ6Ml",
    "outputId": "61ad375d-3c3a-440d-c48d-ce894c0e5d3f"
   },
   "outputs": [],
   "source": [
    "# Fix different spellings of the same breed to increase useable entries\n",
    "\n",
    "# Mismatched spelling of breeds that are affected by merger of df1 and df2 = dd\n",
    "df1['Breed'] = df1['Breed'].str.replace('Airdale Terrier', 'Airedale Terrier')\n",
    "df1['Breed'] = df1['Breed'].str.replace('Cocker Spaniel-American', 'Cocker Spaniel')\n",
    "df1['Breed'] = df1['Breed'].str.replace('Cocker Spaniel-English', 'English Cocker Spaniel')\n",
    "df1['Breed'] = df1['Breed'].str.replace('Collie \\(Rough\\) & \\(Smooth\\)', 'Collie')\n",
    "df1['Breed'] = df1['Breed'].str.replace('Old English Sheepdog \\(Bobtail\\)', 'Old English Sheepdog')\n",
    "df1['Breed'] = df1['Breed'].str.replace('Shetland Sheepdog \\(Sheltie\\)', 'Shetland Sheepdog')\n",
    "\n",
    "df2['Breed'] = df2['Breed'].str.replace('Chinese Shar Pei', 'Chinese Shar-Pei')\n",
    "df2['Breed'] = df2['Breed'].str.replace('Curly Coated Retriever', 'Curly-Coated Retriever')\n",
    "df2['Breed'] = df2['Breed'].str.replace('Soft-coated Wheaten Terrier', 'Soft Coated Wheaten Terrier')\n",
    "\n",
    "# Breeds affected by merger of dd and df3 = dd\n",
    "df1['Breed'] = df1['Breed'].str.replace('Chinese Shar Pei', 'Chinese Shar-Pei')\n",
    "df1['Breed'] = df1['Breed'].str.replace('Curly Coated Retriever', 'Curly-Coated Retriever')\n",
    "df1['Breed'] = df1['Breed'].str.replace('Flat Coated Retriever', 'Flat-Coated Retriever')\n",
    "df1['Breed'] = df1['Breed'].str.replace('Otter Hound', 'Otterhound')\n",
    "df1['Breed'] = df1['Breed'].str.replace('Soft-Coated Wheaten Terrier', 'Soft Coated Wheaten Terrier')\n",
    "\n",
    "# Breeds in that don't make an impact since they are not in df2\n",
    "df1['Breed'] = df1['Breed'].str.replace('Anatolin Sheepdog', 'Anatolian Shepherd Dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wIa_W9cWX8p"
   },
   "source": [
    "*   Create new dataframe from merging the three initial dataframes on 'Breed' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FpSB5QQYKEMB"
   },
   "outputs": [],
   "source": [
    "dd = pd.merge(df1,df2, on='Breed')\n",
    "dd = pd.merge(dd, df3, on='Breed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWOMfnk3WypI"
   },
   "source": [
    "\n",
    "\n",
    "*   Replace all 'na', 'not found' to NaN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45LZ88TCMp9X"
   },
   "outputs": [],
   "source": [
    "dd.replace({'na': 'not found'}, inplace=True)\n",
    "dd.replace({'not found': np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySlyo19-XEi1"
   },
   "source": [
    "\n",
    "\n",
    "*   Drop entry ('Alaskan Malamute') because it is missing height and weight data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7qP0aAF1J4P"
   },
   "outputs": [],
   "source": [
    "dd.dropna(subset=['height_low_inches'], inplace=True)\n",
    "dd.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vrXwlmCR0Ukm"
   },
   "source": [
    "\n",
    "\n",
    "*   Fixed error in values in certain breeds.  Some had height and weight values swapped.\n",
    "\n",
    "** Since data is supposed to reflect AKC values, the fixes were done using values found from the AKC website for those breeds.\n",
    "\n",
    "[AKC website link](https://www.akc.org) where corrected data came from. (Feb 14, 2023)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cqAjLTQu0c8Z"
   },
   "outputs": [],
   "source": [
    "dd.loc[dd[dd['Breed'] == 'Vizsla'].index,['height_low_inches']] = 21\n",
    "dd.loc[dd[dd['Breed'] == 'Vizsla'].index,['height_high_inches']] = 24\n",
    "dd.loc[dd[dd['Breed'] == 'Vizsla'].index,['weight_low_lbs']] = 44\n",
    "dd.loc[dd[dd['Breed'] == 'Vizsla'].index,['weight_high_lbs']] = 60\n",
    "\n",
    "dd.loc[dd[dd['Breed'] == 'Irish Water Spaniel'].index,['height_low_inches']] = 21\n",
    "\n",
    "dd.loc[dd[dd['Breed'] == 'Dandie Dinmont Terrier'].index,['height_low_inches']] = 8\n",
    "dd.loc[dd[dd['Breed'] == 'Dandie Dinmont Terrier'].index,['height_high_inches']] = 11\n",
    "dd.loc[dd[dd['Breed'] == 'Dandie Dinmont Terrier'].index,['weight_low_lbs']] = 18\n",
    "dd.loc[dd[dd['Breed'] == 'Dandie Dinmont Terrier'].index,['weight_high_lbs']] = 24\n",
    "\n",
    "dd.loc[dd[dd['Breed'] == 'Pomeranian'].index,['height_low_inches']] = 6\n",
    "dd.loc[dd[dd['Breed'] == 'Pomeranian'].index,['height_high_inches']] = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-i3yBPxXXQ6p"
   },
   "source": [
    "\n",
    "\n",
    "*   Convert height and weight columns to floats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRHNIXk5XQps"
   },
   "outputs": [],
   "source": [
    "dd['height_low_inches'] = dd['height_low_inches'].astype(str).astype(float)\n",
    "dd['height_high_inches'] = dd['height_high_inches'].astype(str).astype(float)\n",
    "dd['weight_low_lbs'] = dd['weight_low_lbs'].astype(str).astype(float)\n",
    "dd['weight_high_lbs'] = dd['weight_high_lbs'].astype(str).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bO3KhbgLdqHN"
   },
   "source": [
    "*   Remove '%' from the 'obey' column\n",
    "*   Convert 'obey' column to floats\n",
    "*   Change nan in 'obey' to value 0 (these dogs are rated 0%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HmJp6nuldsAQ"
   },
   "outputs": [],
   "source": [
    "# first remove the '%' character\n",
    "dd['obey'] = dd['obey'].str.replace('%', '')\n",
    "\n",
    "# then covert to float\n",
    "dd['obey'] = dd['obey'].astype(str).astype(float)\n",
    "\n",
    "# change nan in 'obey' to 0\n",
    "dd['obey'].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyr3qYoWYy05"
   },
   "source": [
    "### **Adding Features**\n",
    "\n",
    "\n",
    "*   Average weight\n",
    "*   Average height\n",
    "*   Average reps\n",
    "*   Height to weight ratio\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYoPzYQbZI63"
   },
   "outputs": [],
   "source": [
    "dd['weight_avg'] = (dd['weight_high_lbs'] + dd['weight_low_lbs']) / 2\n",
    "dd['height_avg'] = (dd['height_high_inches'] + dd['height_low_inches']) / 2\n",
    "dd['reps_avg'] = (dd['reps_lower'] + dd['reps_upper']) / 2\n",
    "dd['height_to_weight'] = dd['height_avg'] / dd['weight_avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpCVKgYzZ1i_"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **Data Fields of 'dd'**\n",
    "\n",
    "Rows: 113\n",
    "\n",
    "Columns (15):\n",
    "\n",
    "\n",
    "*   'Breed' - Name of AKC dog breed. (string)\n",
    "*   'height_low_inches' - The lower range of dog's height. (float)\n",
    "*   'height_high_inches' - The upper range of a dog's height. (float)\n",
    "*   'weight_low_lbs' - The lower range of dog's weight. (float)\n",
    "*   'weight_high_lbs' - The upper range of dog's weight. (float)\n",
    "*   'Classification' - The size calculation of the dog according to AKC. (string)\n",
    "*   'obey' - The probability that the breed obeys the first command. (float)\n",
    "*   'reps_lower' - The lower limit of repetitions to understand a new command. (int)\n",
    "*   'reps_upper' - The upper limit of repetitions to understand a new command. (int)\n",
    "*   'group' - The AKC group the breed is in. (string)\n",
    "*   'energy_level_value' - A number representing the breed's energy level. (float)\n",
    "*   'demeanor_value' - A number representing the breed's reaction to strangers and other pets. (float)\n",
    "*   'weight_avg' - The average of lower and upper range of dog's weight.\n",
    "*   'height_avg' - The average of lower and upper range of dog's height.\n",
    "*   'reps_avg' - The average of lower and upper range of dog's repetitions to understand a new command.  (float)\n",
    "*   'height_to_weight' - The height_avg / weight_avg.  (float)\n",
    "\n",
    "**NOTE**: 'Classification', 'obey' and all the 'reps' columns show the same information in different ways.  One should only be used as the target and not also a feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fb981bthlPg"
   },
   "source": [
    "\n",
    "**Classification (df2) of 'obey' and reps**<br>\n",
    "Brightest Dogs                                   95%     1 to   4<br>\n",
    "Excellent Working Dogs                           85%     5 to  15<br>\n",
    "Above Average Working Dogs                       70%    16 to  25<br>\n",
    "Average Working/Obedience Intelligence           50%    26 to  40<br>\n",
    "Fair Working/Obedience Intelligence              30%    41 to  80<br>\n",
    "Lowest Degree of Working/Obedience Intelligence   0%    81 to 100<br>\n",
    "<br>\n",
    "**Energy Level**<br>\n",
    "1.0 Needs Lots of Activity<br>\n",
    "0.8 Energetic<br>\n",
    "0.6 Regular Exercise<br>\n",
    "0.4 Calm<br>\n",
    "0.2 Couch Potato<br>\n",
    "<br>\n",
    "**Demeanor**<br>\n",
    "1.0 Outgoing<br>\n",
    "0.8 Friendy<br>\n",
    "0.6 Alert/Responsive<br>\n",
    "0.4 Reserved with Strangers<br>\n",
    "0.2 Aloof/Wary<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRs6OZGwhP27"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **Data Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DaTZiEIS8JeG",
    "outputId": "a8169fb4-faf2-47db-9352-958fc3a85b42"
   },
   "outputs": [],
   "source": [
    "#(j) display dataset information (cleaned)\n",
    "dd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "wf1z8DdXyTz_",
    "outputId": "c78c2c42-27a3-4300-f774-642ec41998e2"
   },
   "outputs": [],
   "source": [
    "#(j) show basic statistics of numeric columns\n",
    "dd[['height_low_inches', 'height_high_inches', 'height_avg', 'weight_low_lbs', 'weight_high_lbs', 'weight_avg', 'height_to_weight']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "iTaeiHFBQd1a",
    "outputId": "e0878fbb-9db2-4036-e7dc-5b0cf5263ca2"
   },
   "outputs": [],
   "source": [
    "#(j) explore distribution of 'obey'\n",
    "dd['obey'].value_counts().sort_index().plot(kind='bar')\n",
    "# majority of dogs are average (50% obey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uc6ljShYR6qp",
    "outputId": "afef2ab4-f69c-46f5-eb5d-82569ab54c81"
   },
   "outputs": [],
   "source": [
    "#(j) view correlation matrix information for 'obey'\n",
    "corr_matrix = dd.corr()\n",
    "corr_matrix['obey'].sort_values()\n",
    "\n",
    "# note: obey = reps values, so of course they have very high correlation,\n",
    "# but they not useful for the analysis.\n",
    "# Highest useable ones include:\n",
    "#   energy_level_value: 0.30\n",
    "#   demeanor_value: 0.15\n",
    "#   height_high_inches: 0.10\n",
    "#   height_to_weight: -0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "CFBgaaoeimBQ",
    "outputId": "84453113-3a1e-44a1-d2e4-dc7f56eb7edc"
   },
   "outputs": [],
   "source": [
    "#(j) Note the correlation between these three features.\n",
    "# Depending on need, we can interchange these features during modeling\n",
    "# a prediction as they suit that type of modeling.\n",
    "ax = sns.scatterplot(data=dd, x='obey', y='reps_avg', hue='Classification')\n",
    "sns.move_legend(ax, 'upper left', bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "D_lPF5fB8JNw",
    "outputId": "499624e9-cca6-4c23-a19f-0435a3c95362"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data = dd, x = 'energy_level_value', y = \"obey\")\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBmeqVHcJMN0"
   },
   "source": [
    "The following bar chart provides insight on dog intelligence by comparing the average obey score of different breed groups in the data set to visualize which breed group is most obedient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "TohURJNE8Ihr",
    "outputId": "879c63a9-2b21-4b16-b1de-0b2604e3c4dc"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "group_obey = dd.groupby('group')['obey'].mean().sort_values(ascending=False)\n",
    "sns.barplot(x=group_obey.index, y=group_obey.values, ax=ax)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=90)\n",
    "ax.set_xlabel('Breed Group')\n",
    "ax.set_ylabel('Avg Obedience Score')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPAY4ctpJAWV"
   },
   "source": [
    "This visualization groups data by breed group, and calculates the mean obey score and energy level score to show the relationship between the average obedience and energy level for each breed group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "5uTzEZQvCDC9",
    "outputId": "bec987f2-9535-490e-9831-bc1bb5e09cc4"
   },
   "outputs": [],
   "source": [
    "group_data = dd.groupby('group').mean()[['obey', 'energy_level_value']].reset_index()\n",
    "sns.scatterplot(data=group_data, x='energy_level_value', y='obey', s=100)\n",
    "plt.xlabel('Energy Level')\n",
    "plt.ylabel('Average Obedience Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXu6dEw4Bq2b"
   },
   "source": [
    "The following visualization is a scatter plot that is comparing the dog breeds intelligence by their weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "EAN5FyL8R5wY",
    "outputId": "8279fc66-f22b-49d5-99ba-5aff5bbcba96"
   },
   "outputs": [],
   "source": [
    "plt.scatter(dd[\"weight_low_lbs\"], dd[\"obey\"])\n",
    "plt.title(\"Weight vs Intelligence\")\n",
    "plt.xlabel(\"Weight (lbs)\")\n",
    "plt.ylabel(\"Intelligence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWc5fOQ_B8DV"
   },
   "source": [
    "The following visualization is a scatter plot which displays the breed by obedience and the dogs demeanor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "AhBgWl-LB5Oy",
    "outputId": "7fb46f5d-74f7-4e16-a561-7ff8c6c33e7e"
   },
   "outputs": [],
   "source": [
    "plt.scatter(dd.obey, dd.demeanor_value)\n",
    "plt.xlabel('Obedience')\n",
    "plt.ylabel('Demeanor')\n",
    "plt.title('Dog Breed by Obedience and Demeanor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPF4ZbJMCDzj"
   },
   "source": [
    "The following bar plot displays the breeds that are most energetic and are sorted by descending energy level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "id": "VuDcPu4RCsJF",
    "outputId": "6210fb40-04a0-407d-c2cd-3f43d94f2531"
   },
   "outputs": [],
   "source": [
    "sorted_df = df3.groupby('group').apply(lambda x: x.sort_values('energy_level_value', ascending=False)).reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='energy_level_value', y='Breed', hue='group', data=sorted_df.groupby('group').head(3), dodge=False)\n",
    "plt.xlabel('Energy Level')\n",
    "plt.ylabel('Breed')\n",
    "plt.title('Most Energetic Dog Breeds by Breed Group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IymbiXsCry8"
   },
   "source": [
    "This heatmap is a visual represenation of the average obedience score for each breed group and weight range. It's filtered for breeds with an average weight of 30 to 60lbs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "MI2iSTFKu7CI",
    "outputId": "17df5a24-e3f7-4693-880b-6e9aaab0b9d8"
   },
   "outputs": [],
   "source": [
    "data_group = dd.groupby(['group', 'weight_avg']).mean().reset_index()\n",
    "filtered = data_group [(data_group ['weight_avg'] >= 30) & (data_group ['weight_avg'] <= 80)]\n",
    "heat_data = filtered.pivot_table(values='obey', index='group', columns='weight_avg')\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.heatmap(heat_data, cmap='Blues', annot=True, fmt='.0f')\n",
    "plt.xlabel('Average Weight (lbs)')\n",
    "plt.ylabel('Breed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-oVpWPadXRC"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **Modeling**\n",
    "\n",
    "\n",
    "*   kNN Classification Model\n",
    "*   kNN Regression Model\n",
    "*   Linear Regression Model\n",
    "*   Polynomial Transformation\n",
    "*   Decision Tree Classifier??\n",
    "*   ??????????????????????\n",
    "\n",
    "Due to the dataset being a small size (113 data points), the train/test split chosen was 80/20.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ekyMA_rOB07O"
   },
   "outputs": [],
   "source": [
    "# Functions used by some of the models\n",
    "def rmse(predicted, actual):\n",
    "  return np.sqrt(((predicted - actual)**2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUYeRe_63Q4p"
   },
   "source": [
    "---\n",
    "### kNN Classification Model\n",
    "Using target 'Classification' which is a category and comparable to 'obey'.<br>\n",
    "Predict what classification (of obedience) a dog is using the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CWPh6wHf3Sd8",
    "outputId": "e5220b2f-3da3-4b2e-ac0a-128126194b03"
   },
   "outputs": [],
   "source": [
    "predictors = ['energy_level_value', 'demeanor_value', 'height_to_weight']\n",
    "target = 'Classification'\n",
    "X = dd[predictors].values\n",
    "y = dd[target].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "for k in range(1,9,2):\n",
    "  knn = KNeighborsClassifier(n_neighbors=k)\n",
    "  knn.fit(X_train, y_train)\n",
    "  predictions = knn.predict(X_test)\n",
    "  accuracy = knn.score(X_test, y_test)\n",
    "  print('k = {}, accuracy = {:.2f}'.format(k, accuracy))\n",
    "\n",
    "# predictors = ['energy_level_value', 'demeanor_value']\n",
    "# k = 1, accuracy = 0.22\n",
    "# k = 3, accuracy = 0.26\n",
    "# k = 5, accuracy = 0.26\n",
    "# k = 7, accuracy = 0.26\n",
    "\n",
    "# predictors = ['energy_level_value', 'demeanor_value', 'height_to_weight']\n",
    "# k = 1, accuracy = 0.35\n",
    "# k = 3, accuracy = 0.39\n",
    "# k = 5, accuracy = 0.48\n",
    "# k = 7, accuracy = 0.39\n",
    "\n",
    "# predictors = ['energy_level_value', 'demeanor_value', 'height_avg', 'weight_avg']\n",
    "# k = 1, accuracy = 0.17\n",
    "# k = 3, accuracy = 0.43\n",
    "# k = 5, accuracy = 0.48\n",
    "# k = 7, accuracy = 0.39"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFLLR1Rr34LQ"
   },
   "source": [
    "The ideal predictors seem to be: 'energy_level_value', 'demeanor_value', 'height_to_weight'.<br>\n",
    "With k = 5, the accuracy is at 48%.  Not great, but better than other attempts on this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "jUz7tuE4mr6-",
    "outputId": "11160eee-fb3e-48c3-f25f-622729e27b56"
   },
   "outputs": [],
   "source": [
    "# kNN classification model for a 'decent' modeling.\n",
    "predictors = ['energy_level_value', 'demeanor_value', 'height_to_weight']\n",
    "target = 'Classification'\n",
    "X = dd[predictors].values\n",
    "y = dd[target].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "accuracy = knn.score(X_test, y_test)\n",
    "print('k = 5, accuracy = {:.2f}'.format(accuracy))\n",
    "\n",
    "# Confusion Matrix to view where the values differed between actual and\n",
    "# predicted.\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.xlabel('predictions')\n",
    "plt.ylabel('actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lo0H_BDbm_GT"
   },
   "source": [
    "The test size was 20%, which is 23 out of 113.  The largest misclassification comes where the data should be 0 but is predicted as 1, at 7/10 being misclassifed.  There is an imbalance in the test dataset with 43% of the test being in category 0.  Then the next largest is 30% for 1.  The majority of category 1 is predicted correctly.  There is only one data point in 2 with it being categorized wrong.  Category 3 was 33% incorrect and category 4 was 100% incorrect with 2 data points.<br><br>\n",
    "The kNN classification model is not well suited to our problem.  The dataset for training and testing is small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qet6v1y5Pwe"
   },
   "source": [
    "---\n",
    "### kNN Regression Model\n",
    "Using target 'obey' which is numeric and comparable to 'Classification'.<br>\n",
    "Predict the value of 'obey' is using the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qrMO3DfK5ndy",
    "outputId": "50ee08dd-e0e7-416b-9f45-986254cb369e"
   },
   "outputs": [],
   "source": [
    "# select the predictor variables and target variables to be used with regression\n",
    "predictors = ['energy_level_value', 'demeanor_value', 'height_to_weight']\n",
    "target = 'obey'\n",
    "X = dd[predictors].values\n",
    "y = dd[target].values\n",
    "\n",
    "# unscaled version (note that scaling is only used on predictor variables)\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# scaled version\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    "\n",
    "# blind prediction of rmse baseline of training data\n",
    "base_rmse = rmse(y_train.mean(), y_test)\n",
    "print('RMSE baseline (test): {:.2f}'.format(base_rmse))\n",
    "\n",
    "for k in range(1,10,2):\n",
    "  knn = KNeighborsRegressor(n_neighbors=k, algorithm=\"brute\")\n",
    "  knn.fit(X_train, y_train)\n",
    "  predictions = knn.predict(X_test)\n",
    "  RMSE = rmse(predictions, y_test)\n",
    "  print('k = {}, RMSE = {:.2f}'.format(k, RMSE))\n",
    "\n",
    "# predictors = ['energy_level_value', 'demeanor_value', 'height_to_weight']\n",
    "# RMSE baseline (test): 19.04\n",
    "# k = 1, RMSE = 28.87\n",
    "# k = 3, RMSE = 22.34\n",
    "# k = 5, RMSE = 20.51\n",
    "# k = 7, RMSE = 19.57\n",
    "# k = 9, RMSE = 21.24\n",
    "\n",
    "# predictors = ['energy_level_value', 'demeanor_value', 'weight_avg', 'height_avg']\n",
    "# RMSE baseline (test): 19.04\n",
    "# k = 1, RMSE = 35.93\n",
    "# k = 3, RMSE = 24.13\n",
    "# k = 5, RMSE = 19.67\n",
    "# k = 7, RMSE = 19.76\n",
    "# k = 9, RMSE = 19.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Az-t6TyOQt2",
    "outputId": "66f758d3-dbc0-4a9d-90fa-517f61443109"
   },
   "outputs": [],
   "source": [
    "def get_train_test_rmse(regr, X_train, X_test, y_train, y_test):\n",
    "    rmse = np.zeros(2)\n",
    "    regr.fit(X_train, y_train)\n",
    "    predict = regr.predict(X_train)\n",
    "    rmse[0] = np.sqrt(((predict - y_train)**2).mean())\n",
    "    predict = regr.predict(X_test)\n",
    "    rmse[1] = np.sqrt(((predict - y_test)**2).mean())\n",
    "    return rmse\n",
    "\n",
    "n = 10\n",
    "test_rmse = []\n",
    "train_rmse = []\n",
    "ks = np.arange(1, n+1, 2)\n",
    "for k in ks:\n",
    "    regr = KNeighborsRegressor(n_neighbors=k, algorithm='brute')\n",
    "    rmse_tr, rmse_te = get_train_test_rmse(regr, X_train, X_test, y_train, y_test)\n",
    "    train_rmse.append(rmse_tr)\n",
    "    test_rmse.append(rmse_te)\n",
    "\n",
    "def get_best(ks, rmse):\n",
    "    best = []\n",
    "    min_rmse = min(rmse)\n",
    "    best.append(ks[rmse.index(min_rmse)])\n",
    "    best.append(min_rmse)\n",
    "    return best\n",
    "\n",
    "best_k, best_rmse = get_best(ks, test_rmse)\n",
    "print('best k = {}, best test RMSE: {:0.1f}'.format(best_k, best_rmse))\n",
    "\n",
    "# predictors = ['energy_level_value', 'demeanor_value', 'height_to_weight']\n",
    "# best k = 7, best test RMSE: 19.6\n",
    "\n",
    "# predictors = ['energy_level_value', 'demeanor_value', 'weight_avg', 'height_avg']\n",
    "# best k = 5, best test RMSE: 19.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "f2AQxtbtOd0W",
    "outputId": "f7226aa3-f779-4f26-9927-c3961e501b39"
   },
   "outputs": [],
   "source": [
    "# kNN regression model using one of the predictor sets.\n",
    "predictors = ['energy_level_value', 'demeanor_value', 'weight_avg', 'height_avg']\n",
    "target = 'obey'\n",
    "X = dd[predictors].values\n",
    "y = dd[target].values\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    "\n",
    "n = 10\n",
    "test_rmse = []\n",
    "train_rmse = []\n",
    "ks = np.arange(1, n+1, 2)\n",
    "for k in ks:\n",
    "    regr = KNeighborsRegressor(n_neighbors=k, algorithm='brute')\n",
    "    rmse_tr, rmse_te = get_train_test_rmse(regr, X_train, X_test, y_train, y_test)\n",
    "    train_rmse.append(rmse_tr)\n",
    "    test_rmse.append(rmse_te)\n",
    "\n",
    "best_k, best_rmse = get_best(ks, test_rmse)\n",
    "print('best k = {}, best test RMSE: {:0.1f}'.format(best_k, best_rmse))\n",
    "\n",
    "# plot RMSE by K\n",
    "plt.plot(ks, train_rmse, label='Train')\n",
    "plt.plot(ks, test_rmse, label='Test')\n",
    "plt.title('RMSE by K')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "behqqpMJPeRD"
   },
   "source": [
    "The two models trained have the best RMSE at about k = 5 or k = 7 with the RMSE at about 19.7.  This is close to the rmse baseline.<br><br>\n",
    "There is some concern on overfitting and why the two lines cross.  I think k = 3 seems to be a good spot.<br><br>\n",
    "** The kNN regression models seems to be objectivly worse than the linear regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTTHGx5uaEVY"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TCin4CmBdbtM",
    "outputId": "d2c5f834-23ba-4fa2-fe3a-7ba77ebdc728"
   },
   "outputs": [],
   "source": [
    "features = ['energy_level_value', 'demeanor_value', 'weight_avg', 'height_avg']\n",
    "#features = ['energy_level_value', 'demeanor_value', 'height_to_weight']\n",
    "X = dd[features]\n",
    "y = dd['obey'].values\n",
    "\n",
    "#Scale X to understand weights better\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# compute training/test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# train model\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "prediction = reg.predict(X_test)\n",
    "\n",
    "# display results\n",
    "print('-----------')\n",
    "print(\"r-square = {:.4f}\".format(reg.score(X_train, y_train)))\n",
    "print('-----------')\n",
    "rmse = np.sqrt(((prediction - y_test)**2).mean())\n",
    "print('rmse: {:.4f}'.format(rmse))\n",
    "print('-----------')\n",
    "print('Intercept: {:.2f}'.format(reg.intercept_))\n",
    "print('Coefficients')\n",
    "for i, feature in enumerate(features):\n",
    "  print('\\t{}: {:.2f}'.format(feature, reg.coef_[i]))\n",
    "print('-----------')\n",
    "\n",
    "# features = ['energy_level_value', 'demeanor_value', 'weight_avg', 'height_avg']\n",
    "# r-square = 0.1897\n",
    "# rmse = 21.9265\n",
    "# Intercept: 53.80\n",
    "# Coefficients\n",
    "#\t  energy_level_value: 8.29\n",
    "#\t  demeanor_value: 5.10\n",
    "#\t  weight_avg: -9.77\n",
    "#\t  height_avg: 8.85\n",
    "\n",
    "# features = ['energy_level_value', 'demeanor_value', 'height_to_weight']\n",
    "# r-square = 0.1636\n",
    "# rmse = 21.5473\n",
    "# Intercept: 54.05\n",
    "# Coefficients\n",
    "#   energy_level_value: 9.29\n",
    "#   demeanor_value: 4.63\n",
    "#\t  height_to_weight: -1.44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAJPEU5PEHtl"
   },
   "source": [
    "The r-squared value is far below the acceptable 0.6 value.  The r-squared for different combinations of features did not exceed 0.19.  That is extremely bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "gCETD2SHtXzw",
    "outputId": "7a05dd5f-502e-415a-97aa-7075097432cb"
   },
   "outputs": [],
   "source": [
    "# plot predicted by actual\n",
    "def plot_actual_predicted(actual, predicted, title):\n",
    "    min_point = min(predicted.min(), actual.min())\n",
    "    max_point = max(predicted.max(), actual.max())\n",
    "    \n",
    "    sns.scatterplot(x=actual, y=predicted)\n",
    "    plt.plot([min_point, max_point], [min_point, max_point], 'k--', linewidth=2)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('actual')\n",
    "    plt.ylabel('predicted')\n",
    "    \n",
    "plot_actual_predicted(y_test, prediction, 'Predicted by actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9RUbbtOEbrry"
   },
   "source": [
    "Each feature was tested individually to see if any are strongly correlated.  The 'energy_level_value' had the strongest correlation, but even on its own it did not noticeably improve the model.  The dataset is not suited to this model since its values do not behave in a linear fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Llr00Z5qZXY"
   },
   "source": [
    "### Polynomial Transformation\n",
    "\n",
    "Incase the data is nonlinear, try to fit polynomial. RMSE went up rapidly with polynomial degree indicating the data is likely more linear than anything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZS4BCZEqc1y",
    "outputId": "8b92a5e3-c0c8-4c6a-cce4-ea2297ab0c3b"
   },
   "outputs": [],
   "source": [
    "features = ['energy_level_value', 'demeanor_value', 'weight_avg', 'height_avg']\n",
    "#features = ['energy_level_value', 'demeanor_value', 'height_to_weight']\n",
    "target = 'obey'\n",
    "X = dd[features].values\n",
    "y = dd[target].values\n",
    "\n",
    "# make a model of polynomial features\n",
    "pf = PolynomialFeatures(degree=2, include_bias=False)\n",
    "pf.fit(X)\n",
    "\n",
    "# transform X so that it has many more features\n",
    "X_poly = pf.transform(X)\n",
    "\n",
    "# compute traning/test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, train_size=0.2, random_state=42)\n",
    "\n",
    "# train model\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "predict_tr = reg.predict(X_train)\n",
    "predict_te = reg.predict(X_test)\n",
    "\n",
    "# display r-squared and rmse\n",
    "print('Polynomial Feature Scores')\n",
    "print(\"r-square = {:.4f}\".format(reg.score(X_train, y_train)))\n",
    "rmse_tr = np.sqrt(((predict_tr - y_train)**2).mean())\n",
    "print(\"RMSE train: {:.4f}\".format(rmse_tr))\n",
    "rmse_te = np.sqrt(((predict_te - y_test)**2).mean())\n",
    "print(\"RMSE test: {:.4f}\".format(rmse_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUVk_uIrq_dI"
   },
   "source": [
    "$r^2$ improved a lot but RMSE is worse. The difference in the rmse between the train and test seems to indicate we have overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G7BFQiD0IPQk",
    "outputId": "e2247e0e-eac5-4cad-f33e-73987b20377f"
   },
   "outputs": [],
   "source": [
    "# check if overfitting by comparing training and test performance\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.2, random_state=42)\n",
    "\n",
    "# train model\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "predict_tr = reg.predict(X_train)\n",
    "predict_te = reg.predict(X_test)\n",
    "\n",
    "# display r-squared and rmse\n",
    "print('Linear Regression Scores')\n",
    "print(\"r-square = {:.4f}\".format(reg.score(X_train, y_train)))\n",
    "rmse_tr = np.sqrt(((predict_tr - y_train)**2).mean())\n",
    "print(\"RMSE train: {:.4f}\".format(rmse_tr))\n",
    "rmse_te = np.sqrt(((predict_te - y_test)**2).mean())\n",
    "print(\"RMSE test: {:.4f}\".format(rmse_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pG7m5gkylP3c"
   },
   "source": [
    "\n",
    "### Decision Tree Classifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1-ARko0zc19"
   },
   "source": [
    "1. Set up baseline for working decision tree classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "075xYQHwmI79"
   },
   "outputs": [],
   "source": [
    "# get predictor and target data\n",
    "predictors = ['energy_level_value', 'demeanor_value', 'weight_avg', 'height_avg']\n",
    "target = ['Classification']\n",
    "X = dd[predictors]\n",
    "y = dd[target].values\n",
    "\n",
    "#split it\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FJBUbUORnR66"
   },
   "outputs": [],
   "source": [
    "# Create DT classifier and train it\n",
    "DT = DecisionTreeClassifier(max_depth=5, random_state=0)\n",
    "DT.fit(X_train,y_train)\n",
    "#convert to pd Series\n",
    "predictions = pd.Series(DT.predict(X_test), name='Predicted')\n",
    "actual = pd.Series(y_test.reshape(1,-1)[0], name='Actual')\n",
    "accuracy = (predictions == actual).sum() / predictions.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhL0qGprzaEy"
   },
   "source": [
    "2. Now that we have a working model, iterated through depths to see where we get the most accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "_a0oMTjgzZkJ",
    "outputId": "68a04dfb-a73c-4f3b-91ee-57148b8da704"
   },
   "outputs": [],
   "source": [
    "depths={}\n",
    "for i in range(1,15):\n",
    "  DT = DecisionTreeClassifier(max_depth=i, random_state=0)\n",
    "  DT.fit(X_train,y_train)\n",
    "  predictions = pd.Series(DT.predict(X_test), name='Predicted')\n",
    "  actual = pd.Series(y_test.reshape(1,-1)[0], name='Actual')\n",
    "  depths[i] = 100* ((predictions == actual).sum() / predictions.shape[0])\n",
    "plt.plot(list(depths.keys()), list(depths.values()))\n",
    "plt.grid()\n",
    "plt.title('Depth vs Accuracy')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Tree Depth');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rjZlOEOqJZNM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Xel-eCt2KFM"
   },
   "source": [
    "- The highest accuracy we were able to acchieve was at a tree depth of 2 \n",
    "  - Accuracy was determined by `100*((predictions == actual).sum() / predictions.shape[0])` \n",
    "- Suspect this is entirely due to limiting the number of buckets we can choose from, forcing the model to sort everything into the middle classifications which have the most entries. Similar to the saying:\n",
    ">\"A broken clock is right twice a day\"\n",
    "\n",
    "3. Generate the depth 2 Decisions Tree Classifier to visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "E5fDk0D_nqmo",
    "outputId": "53672a83-bf90-48a5-da97-21dbe29b0f5e"
   },
   "outputs": [],
   "source": [
    "#Re-generate tree for visualization\n",
    "DT = DecisionTreeClassifier(max_depth=2, random_state=0)\n",
    "DT.fit(X_train,y_train)\n",
    "#visualize tree\n",
    "dot_data = export_graphviz(DT, precision=2,\n",
    "                 feature_names=predictors,  \n",
    "                 proportion=True,  \n",
    "                 filled=True, rounded=True,  \n",
    "                 special_characters=True,\n",
    "                 class_names = list(dd.sort_values('obey')['Classification'].unique()))\n",
    "                 \n",
    "# plot it\n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgFpt1fAdcEt"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJcb3prodfVg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5l4rQ-wdfl7"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **Make a report and video????**\n",
    "also update github stuff?  so much to do."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
